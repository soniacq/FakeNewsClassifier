{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import sub, findall, MULTILINE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from unicodedata import normalize\n",
    "from json import loads\n",
    "from csv import reader,writer,QUOTE_ALL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk import FreqDist, pos_tag\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pickle import load\n",
    "from operator import itemgetter\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_description = {\n",
    "    0: 'conjunction, coordinating', 1: 'numeral, cardinal',\n",
    "    2: 'determiner', 3: 'foreign word', 4: 'preposition or conjunction, subordinating',\n",
    "    5: 'adjective or numeral, ordinal', 6: 'adjective, comparative',\n",
    "    7: 'adjective, superlative', 8: 'modal auxiliary',                    \n",
    "    9: 'noun, common, singular or mass', 10: 'noun, proper, singular',\n",
    "    11: 'noun, proper, plural', 12: 'noun, common, plural', 13:'pre-determiner',\n",
    "    14: 'genitive marker', 15: 'pronoun, personal', 16: 'pronoun, possessive',\n",
    "    17: 'adverb', 18: 'adverb, comparative', 19: 'adverb, superlative',\n",
    "    20: 'particle', 21: '\"to\" as preposition/infinitive',\n",
    "    22: 'interjection', 23: 'verb, base form', 24: 'verb, past tense',\n",
    "    25: 'verb, present participle or gerund', 26: 'verb, past participle',\n",
    "    27: 'verb, present tense, not 3rd person singular',\n",
    "    28: 'verb, present tense, 3rd person singular', 29: 'WH-determiner', 30: 'WH-pronoun',\n",
    "    31: 'WH-pronoun, possessive',32: 'Wh-adverb',33:'number of words', 34:'number of words per sentence',\n",
    "    35: 'number of captalized words',36: 'percentage of stopwords', 37:'number of punctuation',\n",
    "    38:'number of quotes', 39:'number of URls'    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ulr_corpus(text):\n",
    "    new_text = sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', text, flags=MULTILINE)\n",
    "    count_matches = len(findall(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))',text))\n",
    "    return new_text, count_matches\n",
    "\n",
    "def remove_stopwords_corpus(text):\n",
    "    content = []\n",
    "    for w in text:\n",
    "        if w.lower().strip() not in stopwords.words('english'):\n",
    "            content.append(w.lower().strip())\n",
    "\n",
    "    return content\n",
    "\n",
    "def remove_mention_corpus(text):\n",
    "    new_text = sub(r'@\\w+ ?','',text)\n",
    "    count_matches = len(findall(r'@\\w+ ?',text))\n",
    "    \n",
    "    return new_text, count_matches\n",
    "\n",
    "def tokenizer(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "#\"WP$\":0,\n",
    "\n",
    "\n",
    "#\"WP$\":0,\n",
    "#'WH-pronoun, possessive' 31 WP$\n",
    "#'interjection’  22 UH\n",
    "#'genitive marker' 14\n",
    "#'pre-determiner'   13\n",
    "#‘adverb, superlative'.   19\n",
    "#'foreign word'    3\n",
    "\n",
    "# 0: 'conjunction, coordinating', 1: 'numeral, cardinal',\n",
    "#    2: 'determiner', 3: 'foreign word', 4: 'preposition or conjunction, subordinating',\n",
    "#    5: 'adjective or numeral, ordinal', 6: 'adjective, comparative',\n",
    "#    7: 'adjective, superlative', 8: 'modal auxiliary',                    \n",
    "#    9: 'noun, common, singular or mass', 10: 'noun, proper, singular',\n",
    "##    11: 'noun, proper, plural', 12: 'noun, common, plural', 13:'pre-determiner',\n",
    "#    14: 'genitive marker', 15: 'pronoun, personal', 16: 'pronoun, possessive',\n",
    "#    17: 'adverb', 18: 'adverb, comparative', 19: 'adverb, superlative',\n",
    "#    20: 'particle', 21: '\"to\" as preposition/infinitive',\n",
    "#    22: 'interjection', 23: 'verb, base form', 24: 'verb, past tense',\n",
    "#    25: 'verb, present participle or gerund', 26: 'verb, past participle',\n",
    " #   27: 'verb, present tense, not 3rd person singular',\n",
    " #   28: 'verb, present tense, 3rd person singular', 29: 'WH-determiner', 30: 'WH-pronoun',\n",
    " #   31: 'WH-pronoun, possessive',32: 'Wh-adverb',33:'number of words', 34:'number of words per sentence',\n",
    " #   35: 'number of captalized words',36: 'percentage of stopwords', 37:'number of punctuation',\n",
    " #   38:'number of quotes', 39: 'author',40:'basic_tags', 41:'formatting_tags', 42:'forms_inputs_tags',\n",
    " #   43:'frames_tags', 44:'images_tags', 45:'audio_video_tags', 46:'links_tags',\n",
    " #   47:'lists_tags', 48:'tables_tags', 49:'semantics_tags', 50:'metainfo_tags',\n",
    " #   51:'programming_tags', 52:'advertisement'\n",
    "            \n",
    "  #  word_tagged_dict = {\"CC\":0, \"CD\":0, \"DT\":0, \"FW****\":0, \"IN\":0, \n",
    "                      #  \"JJ\":0, \"JJR\":0,\"JJS\":0, \"MD\":0, \"NN\":0,\n",
    "                       # \"NNP\":0, \"NNPS\":0, \"NNS\":0,\"PDT*****\":0, \"POS****\":0, \n",
    "                        #\"PRP\":0, \"PRP$\":0, \"RB****\":0, \"RBR\":0, \"RBS***\":0,\n",
    "                       # \"RP\":0, \"TO\":0, \"UH****\":0, \"VB\":0, \"VBD\":0, \n",
    "                       # \"VBG\":0, \"VBN\":0,\"VBP\":0, \"VBZ\":0, \"WDT\":0,\n",
    "                        #\"WP\":0, \"WRB\":0}            \n",
    "def part_of_speech_tagger(tokens):\n",
    "    ''' \n",
    "    More details in nltk.help.upenn_tagset()\n",
    "        CC, CD, DT, FW, IN, JJ, JJR, JJS, LS, MD, NN, NNP,\n",
    "        NNPS, NNS, PDT, POS, PRP, PRP$, RB, RBR, RBS, RP, SYM,\n",
    "        TO, UH, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WP$, WRB\n",
    "    '''\n",
    "    word_tagged_dict = {\"CC\":0, \"CD\":0, \"DT\":0, \"FW\":0, \"IN\":0, \n",
    "                            \"JJ\":0, \"JJR\":0,\"JJS\":0, \"MD\":0, \"NN\":0,\n",
    "                            \"NNP\":0, \"NNPS\":0, \"NNS\":0,\"PDT\":0, \"POS\":0, \n",
    "                            \"PRP\":0, \"PRP$\":0, \"RB\":0, \"RBR\":0, \"RBS\":0,\n",
    "                            \"RP\":0, \"TO\":0, \"UH\":0, \"VB\":0, \"VBD\":0, \n",
    "                            \"VBG\":0, \"VBN\":0,\"VBP\":0, \"VBZ\":0, \"WDT\":0,\n",
    "                            \"WP\":0, \"WP$\":0, \"WRB\":0} \n",
    "\n",
    "    word_tagged_list, result = pos_tag(tokens), []\n",
    "    for item in  word_tagged_list:\n",
    "        if(item[1] in word_tagged_dict.keys()):\n",
    "            word_tagged_dict[item[1]] += 1\n",
    "\n",
    "    word_tagged_sorted = sorted(word_tagged_dict.items(), key=itemgetter(0))\n",
    "    word_tagged_list = []\n",
    "    for i in word_tagged_sorted:\n",
    "        word_tagged_list.append(i[1])\n",
    "    #word_tagged_list.pop(10)\n",
    "    #word_tagged_list.pop(30)\n",
    "    return word_tagged_list\n",
    "\n",
    "def count_captalized_words(tokens):\n",
    "    nro_upper_words = 0\n",
    "    for i in tokens:\n",
    "        if(i.isupper()):\n",
    "            nro_upper_words += 1\n",
    "    return nro_upper_words\n",
    "\n",
    "def count_per_stopwords(tokens):\n",
    "    total_words, words_per_sent = len(tokens), 0.0\n",
    "    stopwords_nltk = stopwords.words('english')\n",
    "    count = 0\n",
    "    for w in tokens:\n",
    "        if w.lower().strip() in stopwords_nltk:\n",
    "            count += 1\n",
    "    if(total_words > 0):\n",
    "        words_per_sent = round(count/total_words,2)\n",
    "    return words_per_sent\n",
    "\n",
    "def count_punctuation(text, regular_exp):\n",
    "    #r'[' + punctuation+ r']+' and r'[\"\\']+'\n",
    "    count = 0\n",
    "    tokenizer = RegexpTokenizer(regular_exp)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    count = len(tokens)\n",
    "\n",
    "    return count\n",
    "\n",
    "def count_quotes(text):\n",
    "    count = 0\n",
    "    tokenizer = RegexpTokenizer(r'[\"\\']+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    count = len(tokens)\n",
    "\n",
    "    return count\n",
    "\n",
    "def sentence_level_attr(text, tokens):\n",
    "    word_count, word_sent = 0, 0\n",
    "    words_per_sent = 0.0\n",
    "\n",
    "    #word count of the whole text\n",
    "    vocabulary = FreqDist(tokens)\n",
    "    word_count = len(vocabulary.keys())\n",
    "\n",
    "    #word count by setence\n",
    "    sent_tokenize_list = sent_tokenize(text)\n",
    "    for i in sent_tokenize_list:\n",
    "        tkn = tokenizer(i)\n",
    "        vocabulary = FreqDist(tkn)\n",
    "        word_sent += len(vocabulary.keys())\n",
    "\n",
    "    if(len(sent_tokenize_list) > 0):\n",
    "        words_per_sent = round(word_sent/len(sent_tokenize_list), 2)\n",
    "\n",
    "    return word_count, words_per_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(X):\n",
    "    lines = np.shape(X)[0]\n",
    "    columns = np.shape(X)[1]    \n",
    "    result = {}\n",
    "    \n",
    "    for i in range(columns):\n",
    "        \n",
    "        list_probabilities = []\n",
    "        sum_values,entropy  = 0.0, 0.0\n",
    "        for j in range(lines):\n",
    "            sum_values += X[j][i]\n",
    "        for j in range(lines):\n",
    "            if(sum_values > 0):\n",
    "                list_probabilities.append(X[j][i]/sum_values)\n",
    "            else:\n",
    "                list_probabilities.append(0.0)\n",
    "        \n",
    "        for pi in list_probabilities:\n",
    "            if pi > 0:\n",
    "                entropy +=  pi * log(pi, 2)\n",
    "                \n",
    "        if(entropy != 0.0):\n",
    "            entropy = entropy/log(lines,2)*(-1)\n",
    "        else:\n",
    "            entropy = 0.0\n",
    "        \n",
    "        result[i] = entropy\n",
    "            \n",
    "    return result\n",
    "\n",
    "def plot_entropy_bar_chart(entropy_attr_values, range_ranking):\n",
    "\n",
    "    top_attr = sorted(entropy_attr_values.items(), key=itemgetter(1),reverse=True)[:range_ranking]\n",
    "    \n",
    "    x,y = [],[]\n",
    "    for i in top_attr:\n",
    "        #print(attr_description[i[0]],'=>\\t',i[1])\n",
    "        x.append(attr_description[i[0]])\n",
    "        y.append(i[1])\n",
    "        \n",
    "    plt.figure(figsize=(10,15))\n",
    "    plt.title(\"Entropy Features Values\")\n",
    "\n",
    "    plt.barh(range(len(top_attr)), y,\n",
    "           color=\"r\", align=\"center\")\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(range(len(top_attr)), x,fontsize=15)\n",
    "    #plt.ylim([-1, top_10_attr])\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics_metric_value(metric_list):\n",
    "    mean_list = [0,0]\n",
    "    elements_class = []\n",
    "    z_critical = stats.norm.ppf(q = 0.975) #1.959963984540054\n",
    "    result = {0:[], 1:[]}\n",
    "    for i in range(0,len(mean_list)):\n",
    "        for j in metric_list:\n",
    "            mean_list[i] += j[i]\n",
    "            elements_class.append(j[i])\n",
    "\n",
    "        standard_dev = statistics.stdev(elements_class) \n",
    "        margin_of_error = z_critical * (standard_dev/sqrt(len(elements_class)))\n",
    "        confidence_interval = \"{:4.2f}\".format(margin_of_error)\n",
    "        \n",
    "        mean_list[i] = mean_list[i]/len(metric_list)\n",
    "\n",
    "        #result[i] = [\"{:2.4f}\".format(mean_list[i]), confidence_interval]\n",
    "        result[i] = \"{:2.4f}\".format(mean_list[i])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_mean_confmatrix(confusion_list):\n",
    "    result = [[0.0,0.0],[0.0,0.0]]\n",
    "    for cm in confusion_list:\n",
    "        for i in range(0,len(result)):\n",
    "            for j in range(0,len(result)):\n",
    "                result[i][j] += cm[i][j]\n",
    "    for i in range(0,len(result)):\n",
    "        for j in range(0,len(result)):\n",
    "            result[i][j] = result[i][j]/len(confusion_list)\n",
    "    return result\n",
    "\n",
    "def show_confusion_matrix(cm):\n",
    "    for i in cm:\n",
    "        a = \"{:.2f}\".format(i[0])\n",
    "        b = \"{:.2f}\".format(i[1])\n",
    "        print(\"[\"+a+\" \"+b+\"]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "text, count_urls = remove_ulr_corpus(\"Hello home how are you!!!,,, - dd\")\n",
    "tokens = tokenizer(text)\n",
    "\n",
    "pos_tag_numbers   = part_of_speech_tagger(tokens)\n",
    "word_count, words_per_sent = sentence_level_attr(text,tokens)\n",
    "nr_captalized_words  = count_captalized_words(tokens)\n",
    "nr_per_stopwords = count_per_stopwords(tokens)\n",
    "nr_punctuation = count_punctuation(text,r'['+punctuation+r']+')\n",
    "nr_quotes = count_punctuation(text,r'[\"\\']+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
