{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from utils.ipynb\n",
      "Importing Jupyter notebook from WWW_classifier_experiments_features.ipynb\n",
      "Importing Jupyter notebook from extract_save_features.ipynb\n",
      "Importing Jupyter notebook from web_markup_features.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'web_markup_features' from 'web_markup_features.ipynb'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPORTING EXTERNAL JUPYTER NOTEBOOKS\n",
    "import nbimporter\n",
    "from WWW_classifier_experiments_features import *\n",
    "from extract_save_features import *\n",
    "from web_markup_features import *\n",
    "# import nltk_linguistic_features as nltk_linguis_features\n",
    "import utils as utils\n",
    "from importlib import reload\n",
    "import sys\n",
    "\n",
    "# reload(sys.modules['readability'])\n",
    "# reload(sys.modules['nltk_linguistic_features'])\n",
    "reload(sys.modules['utils'])\n",
    "reload(sys.modules['step4_WWW_classifier_experiments_features']) # WWW_Classifier_Experiments\n",
    "reload(sys.modules['extract_save_features'])\n",
    "reload(sys.modules['step1_web_markup_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying classifier over the test dataset using invariant features. To classifiers SGD and RandomForest. They needs float data\n",
    "def test_classifier_floatdata(dir_file_test_fake, dir_file_test_msm, classifier, typefeatures, type_text, filter_features):\n",
    "    X_fakenews, fakenews_labels_list, fakenews_list_urls = extract_features_filter(typefeatures, type_text, dir_file_test_fake, 1, filter_features ) #1 means fake news. \n",
    "    X_msmnews, msmnews_labels_list, msmnews_list_urls = extract_features_filter(typefeatures, type_text, dir_file_test_msm, 0, filter_features)#0 means true news.\n",
    "    X_temp = np.asarray(X_fakenews+ X_msmnews)\n",
    "    new_X = []\n",
    "    for i in X_temp:\n",
    "        desired_array =  i.astype(np.float) #convert string  arrays to float arrays\n",
    "        new_X.append(desired_array)\n",
    "    X = new_X\n",
    "    y_true = np.asarray(fakenews_labels_list + msmnews_labels_list) \n",
    "    y_pred = classifier.predict(X) \n",
    "    return [y_true, y_pred]\n",
    "\n",
    "#Applying classifier over the test dataset using invariant features\n",
    "def test_classifier_domain(dir_file_test_fake, dir_file_test_msm, classifier, typefeatures, type_text, filter_features):\n",
    "    X_fakenews, fakenews_labels_list, fakenews_list_urls = extract_features_filter(typefeatures, type_text, dir_file_test_fake, 1, filter_features ) #1 means fake news. \n",
    "    X_msmnews, msmnews_labels_list, msmnews_list_urls = extract_features_filter(typefeatures, type_text, dir_file_test_msm, 0, filter_features)#0 means true news.\n",
    "    X = np.asarray(X_fakenews+ X_msmnews)\n",
    "    #print (X)\n",
    "    y_true = np.asarray(fakenews_labels_list + msmnews_labels_list) \n",
    "    y_pred = classifier.predict(X) \n",
    "    return [y_true, y_pred]\n",
    "\n",
    "#compute metrics\n",
    "def compute_metrics_avg(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted') \n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    #print (\"Accuracy: \" + str(accuracy) + \" \\n Precision: \" + str(precision) + \" \\n Recall: \" + str(recall) +  \" \\n F1_score: \" + str(f1) + \" \\n Confusion Matrix(tn, fp, fn, tp): \" + str(tn) +\", \"+ str(fp) +\", \"+ str(fn) +\", \"+ str(tp) + \" \\n\")\n",
    "    return [accuracy, precision, recall, f1]\n",
    "    \n",
    "def compute_metrics(array_metrics):\n",
    "    return compute_metrics_avg(array_metrics[0], array_metrics[1])\n",
    "\n",
    "#Applying classifier over the test dataset using invariant features\n",
    "def classifier_noGT(dir_file_test_data, classifier, typefeatures, type_text, filter_features):\n",
    "    X_temp, labels_list, list_urls = extract_features_filter(typefeatures, type_text, dir_file_test_data, 1, filter_features ) \n",
    "    X = np.asarray(X_temp)\n",
    "    y_pred = classifier.predict(X) \n",
    "    return [list_urls, y_pred]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running TAG Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function run_classifier: this function runs the classifier.\n",
    "# variables:\n",
    "# typeFeatures could be: 'tagF'=TopicAgnostic features, 'linguisticF'=Linguistic features, 'webmarkupF'=Webmarkup features\n",
    "# trainTestData = [[train_fake_files], [train_msm_files], [test_fake_files], [test_msm_files]]\n",
    "def run_classifier(typeFeatures, type_text, path_data, trainTestData, filter_features):\n",
    "    train_fake_files = trainTestData[0]\n",
    "    train_msm_files = trainTestData[1]\n",
    "    test_fake_files = trainTestData[2]\n",
    "    test_msm_files = trainTestData[3]\n",
    "    \n",
    "    mean_results_knn = [0,0,0,0]\n",
    "    mean_results_svm = [0,0,0,0]\n",
    "    mean_results_sgd = [0,0,0,0]\n",
    "    mean_results_rf = [0,0,0,0]\n",
    "\n",
    "    total_datasets = len(train_fake_files)\n",
    "    for index in range(total_datasets):\n",
    "        #Content Based approach...\n",
    "        #Getting features vector from dataset\n",
    "        X_fakenews, fakenews_labels_list, fakenews_list_urls = extract_features_filter(typeFeatures, type_text, path_data+ train_fake_files[index], 1, filter_features ) #1 means fake news. \n",
    "        X_msmnews, msmnews_labels_list, msmnews_list_urls = extract_features_filter(typeFeatures, type_text, path_data+ train_msm_files[index], 0, filter_features)#0 means true news.\n",
    "        X = np.asarray(X_fakenews+ X_msmnews) \n",
    "        Y = np.asarray(fakenews_labels_list + msmnews_labels_list)\n",
    "\n",
    "        #Training classifier\n",
    "#         print('\\nK-Nearest Neighbor:')\n",
    "        knn_classifier_sy = KNeighborsClassifier(n_neighbors=20)\n",
    "        knn_classifier_sy.fit(X,Y)#training\n",
    "#         print('\\nSupport Vector Machine:')\n",
    "        svm_classifier_sy = svm.SVC(kernel = 'linear', C=0.001)#kernel = 'linear'\n",
    "        svm_classifier_sy.fit(X,Y)#training\n",
    "\n",
    "#         print('\\nStochastic Gradient Descent:')\n",
    "        sgd_classifier_sy = SGDClassifier(loss=\"log\", penalty=\"elasticnet\")\n",
    "        sgd_classifier_sy.fit(X,Y)\n",
    "#         print('\\nRandom Forest:')\n",
    "        rf_classifier_sy = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)#max_depth=2, random_state=0)\n",
    "        rf_classifier_sy.fit(X,Y)\n",
    "\n",
    "        #test dataset \n",
    "        dir_file_test_fake =path_data+ test_fake_files[index]\n",
    "        dir_file_test_msm =path_data+ test_msm_files[index]\n",
    "        measures_knn = compute_metrics(test_classifier_domain(dir_file_test_fake, dir_file_test_msm, knn_classifier_sy, typeFeatures, type_text, filter_features))\n",
    "        measures_svm = compute_metrics(test_classifier_domain(dir_file_test_fake, dir_file_test_msm, svm_classifier_sy, typeFeatures, type_text, filter_features))\n",
    "        measures_sgd = compute_metrics(test_classifier_floatdata(dir_file_test_fake, dir_file_test_msm, sgd_classifier_sy, typeFeatures, type_text, filter_features))\n",
    "        measures_rf = compute_metrics(test_classifier_floatdata(dir_file_test_fake, dir_file_test_msm, rf_classifier_sy, typeFeatures, type_text, filter_features))\n",
    "\n",
    "        number_measures = 4\n",
    "        for j in range(number_measures):\n",
    "            mean_results_knn[j] = mean_results_knn[j] + measures_knn[j]\n",
    "            mean_results_svm[j] = mean_results_svm[j] + measures_svm[j]\n",
    "            mean_results_sgd[j] = mean_results_sgd[j] + measures_sgd[j]\n",
    "            mean_results_rf[j] = mean_results_rf[j] + measures_rf[j]\n",
    "    \n",
    "    print (\"Accuracy KNN: \" + str(mean_results_knn[0]/total_datasets) )\n",
    "    print (\"Accuracy SVM: \" + str(mean_results_svm[0]/total_datasets)  )  \n",
    "    print (\"Accuracy SDG: \" + str(mean_results_sgd[0]/total_datasets) )\n",
    "    print (\"Accuracy RF: \" + str(mean_results_rf[0]/total_datasets)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without ground-truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function run_classifier: this function runs the classifier without a ground truth.\n",
    "# variables:\n",
    "# typeFeatures could be: 'tagF'=TopicAgnostic features, 'linguisticF'=Linguistic features, 'webmarkupF'=Webmarkup features\n",
    "# trainTestData = [[train_fake_files], [train_msm_files], [test_fake_files], [test_msm_files]]\n",
    "def run_classifier_noGT(typeFeatures, type_text, path_data, trainTestData, filter_features):\n",
    "    train_fake_files = trainTestData[0]\n",
    "    train_msm_files = trainTestData[1]\n",
    "    test_data = trainTestData[2]\n",
    "    \n",
    "    total_datasets = len(train_fake_files)\n",
    "    for index in range(total_datasets):\n",
    "        #Content Based approach...\n",
    "        #Getting features vector from dataset\n",
    "        X_fakenews, fakenews_labels_list, fakenews_list_urls = extract_features_filter(typeFeatures, type_text, path_data+ train_fake_files[index], 1, filter_features ) #1 means fake news. \n",
    "        X_msmnews, msmnews_labels_list, msmnews_list_urls = extract_features_filter(typeFeatures, type_text, path_data+ train_msm_files[index], 0, filter_features)#0 means true news.\n",
    "        X = np.asarray(X_fakenews+ X_msmnews) \n",
    "        Y = np.asarray(fakenews_labels_list + msmnews_labels_list)\n",
    "\n",
    "        #Training classifier\n",
    "        svm_classifier_sy = svm.SVC(kernel = 'linear', C=0.001)#kernel = 'linear'\n",
    "        svm_classifier_sy.fit(X,Y)#training\n",
    "\n",
    "        #test dataset \n",
    "        dir_file_test_data =path_data+ test_data[index]\n",
    "        output_svm = classifier_noGT(dir_file_test_data, svm_classifier_sy, typeFeatures, type_text, filter_features)\n",
    "        print('CLASSIFIER RESULTS: ')\n",
    "        print (\"list_urls\")\n",
    "        print (output_svm[0])\n",
    "        print (\"y_pred\")\n",
    "        print (output_svm[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature that will be filtered. The arrays contain the feature's indexes. Those features were selected after feature engeeniering\n",
    "#HEADLINES\n",
    "h_liwc_filter = [85, 55, 74, 77]\n",
    "h_readability_filter = [7, 18]\n",
    "h_nlkt_filter = [3, 4, 6, 16, 21, 24, 25, 28, 31, 32]\n",
    "headline_filter_features = [h_liwc_filter, h_readability_filter, h_nlkt_filter]\n",
    "\n",
    "#CONTENT\n",
    "c_liwc_filter = [23, 24, 25, 26, 27, 28]\n",
    "c_readability_filter = []\n",
    "c_nlkt_filter = []\n",
    "content_filter_features = [c_liwc_filter, c_readability_filter, c_nlkt_filter]\n",
    "\n",
    "#HEAD_CONTENT\n",
    "hc_liwc_filter = [23, 24, 25, 26, 27, 28]\n",
    "hc_readability_filter = []\n",
    "hc_nlkt_filter = [2, 7, 13, 14, 18, 19, 22, 32]\n",
    "headline_content_filter_features = [hc_liwc_filter, hc_readability_filter, hc_nlkt_filter]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.nbcnews.com/politics/2020-election/dems-alter-how-they-run-campaigns-prove-liberal-values-dodge-n984576\n",
      "article--\n",
      "Writing... 1\n",
      "[Warning] LIWIC features were not extracted. Please extract those manually and update the output cvs file. Remenber this is just optional.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.nbcnews.com/politics/2020-election/dems-alter-how-they-run-campaigns-prove-liberal-values-dodge-n984576'\n",
    "output_file_name = '/Users/.../Fakenews/paper_fn/Experiments/data/discovery_paper/test_discoveryCrawlData.csv'\n",
    "\n",
    "get_WebFeatures_from_url(url, output_file_name)\n",
    "#extract LIWIC features manually (it is optional)\n",
    "get_save_Readability_NLTK_features(output_file_name, 2)# 2 = content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testjson.csv\n",
      "infowarsnews_sample.html\n",
      "testjsonfile1.json\n",
      "2, \n",
      "done\n",
      "[Warning] LIWIC features were not extracted. Please extract those manually and update the output cvs file. Remenber this is just optional.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_directory = '/Users/.../Fakenews/paper_fn/Experiments/data/discovery_paper/testjson/'\n",
    "output_file_name = '/Users/.../Fakenews/paper_fn/Experiments/data/discovery_paper/testjson/testjson.csv'\n",
    "\n",
    "get_WebFeatures_from_directory_json(path_directory, output_file_name)\n",
    "#extract LIWIC features manually (it is optional)\n",
    "get_save_Readability_NLTK_features(output_file_name, 1)# 2 = content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification without ground Truth (noGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER RESULTS: \n",
      "list_urls\n",
      "['https://www.infowars.com/trump-put-more-women-in-top-roles-than-obama-bush-clinton/']\n",
      "y_pred\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/Users/.../Fakenews/paper_fn/Experiments/data/domain_agnostic/\"\n",
    "\n",
    "train_fake_files = ['LIWC2015_fakenews_celebrity_content.csv'] #'LIWC2015_fakenews_celebrity.csv','LIWC2015_fakenews_celebrity_content.csv','LIWC2015_fakenews_celebrity_headContent.csv']\n",
    "train_msm_files = ['LIWC2015_realnews_celebrity_content.csv'] #'LIWC2015_realnews_celebrity.csv' , 'LIWC2015_realnews_celebrity_content.csv', 'LIWC2015_realnews_celebrity_headContent.csv']\n",
    "dir_file_test_data = ['testjson.csv']\n",
    "\n",
    "features = [['linguisticF_NLTK',  'readabilityF','webmarkupF'], []]\n",
    "typeFeatures = features[0]\n",
    "type_text = 2\n",
    "filter_features = content_filter_features\n",
    "run_classifier_noGT(typeFeatures, type_text, path_data, [train_fake_files, train_msm_files, dir_file_test_data], filter_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effectiveness for Different Topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN: 0.6929955290611028\n",
      "Accuracy SVM: 0.7660208643815202\n",
      "Accuracy SDG: 0.7287630402384501\n",
      "Accuracy RF: 0.7496274217585693\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/Users/.../Fakenews/paper_fn/Experiments/data/domain_agnostic/\"\n",
    "\n",
    "train_fake_files = ['LIWC2015_fakenews_NYUcrawl_headContent.csv'] #'LIWC2015_fakenews_celebrity.csv','LIWC2015_fakenews_celebrity_content.csv','LIWC2015_fakenews_celebrity_headContent.csv']\n",
    "train_msm_files = ['LIWC2015_realnews_NYUcrawl_headContent.csv'] #'LIWC2015_realnews_celebrity.csv' , 'LIWC2015_realnews_celebrity_content.csv', 'LIWC2015_realnews_celebrity_headContent.csv']\n",
    "test_files = ['LIWC2015_fakenews_celebrity_content.csv']#'LIWC2015_fakenews_political2016.csv' ,'LIWC2015_fakenews_political2016_content.csv','LIWC2015_fakenews_political2016_headContent.csv']\n",
    "\n",
    "features = [['linguisticF_NLTK',  'readabilityF','webmarkupF'], []]\n",
    "typeFeatures = features[0]\n",
    "type_text = 2\n",
    "filter_features = content_filter_features\n",
    "run_classifier_noGT(typeFeatures, type_text, path_data, [train_fake_files, train_msm_files, test_files], filter_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy KNN: 0.603448275862069\n",
      "Accuracy SVM: 0.6336206896551724\n",
      "Accuracy SDG: 0.5517241379310345\n",
      "Accuracy RF: 0.603448275862069\n"
     ]
    }
   ],
   "source": [
    "path_data = \"/Users/.../Fakenews/paper_fn/Experiments/data/domain_agnostic/\"\n",
    "\n",
    "test_fake_files = ['LIWC2015_fakenews_celebrity_content.csv'] #'LIWC2015_fakenews_celebrity.csv','LIWC2015_fakenews_celebrity_content.csv','LIWC2015_fakenews_celebrity_headContent.csv']\n",
    "test_msm_files = ['LIWC2015_realnews_celebrity_content.csv'] #'LIWC2015_realnews_celebrity.csv' , 'LIWC2015_realnews_celebrity_content.csv', 'LIWC2015_realnews_celebrity_headContent.csv']\n",
    "train_fake_files = ['LIWC2015_fakenews_political2016_content.csv']#'LIWC2015_fakenews_political2016.csv' ,'LIWC2015_fakenews_political2016_content.csv','LIWC2015_fakenews_political2016_headContent.csv']\n",
    "train_msm_files = ['LIWC2015_realnews_political2016_content.csv'] #'LIWC2015_realnews_political2016.csv' , 'LIWC2015_realnews_political2016_content.csv', 'LIWC2015_realnews_political2016_headContent.csv']\n",
    "\n",
    "features = [['linguisticF_NLTK', 'linguisticF_LIWC',  'readabilityF','webmarkupF']]\n",
    "typeFeatures = features[0]\n",
    "type_text = 2\n",
    "filter_features = content_filter_features\n",
    "run_classifier(typeFeatures, type_text, path_data, [train_fake_files, train_msm_files, test_fake_files, test_msm_files], filter_features)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
